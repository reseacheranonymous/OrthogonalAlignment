<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Anonymous Project Page</title>
  <style>
:root{--bg:#ffffff;--fg:#111;--muted:#555;--box:#fafafa;--border:#eaeaea;--link:#0b5fff;}
@media (prefers-color-scheme: dark){
  :root{--bg:#0b0b0b;--fg:#f2f2f2;--muted:#b5b5b5;--box:#131313;--border:#2a2a2a;--link:#6aa6ff;}
}
body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica,Arial,sans-serif;
     background:var(--bg);color:var(--fg);line-height:1.6;margin:0;}
.container{max-width:980px;margin:40px auto;padding:0 18px;}
h1{font-size:2.0rem;margin:0 0 8px 0;}
h2{margin-top:32px;}
a{color:var(--link);text-decoration:none;}
a:hover{text-decoration:underline;}
.box{background:var(--box);border:1px solid var(--border);border-radius:14px;padding:14px 16px;margin:16px 0;}
.small{color:var(--muted);font-size:0.95rem;}
.nav{display:flex;gap:14px;flex-wrap:wrap;margin-top:8px;margin-bottom:14px}
iframe{width:100%;height:820px;border:1px solid var(--border);border-radius:14px;}
hr{border:none;border-top:1px solid var(--border);margin:28px 0;}
img{max-width:100%;height:auto;border-radius:10px;border:1px solid var(--border);}
code, pre{background:var(--box);border:1px solid var(--border);border-radius:10px;}
pre{padding:12px;overflow:auto;}
</style>
</head>
<body>
  <div class="container">
    <h1>Cross-attention Performs Orthogonal Alignment in Recommendation Models</h1>
    <div class="box">
      <div><b>Status:</b> Under review (ICML submission)</div>
      <div><b>Materials:</b> <a href="OA_ICML_anonymous.mp4">video (MP4)</a> ¬∑ <a href="OA_ICML_anonymous_clean.pdf">slides (PDF)</a></div>
      <div class="small">This page is fully-anonymized for double-blind review. Identifying links and metadata have been strickly removed.</div>
    </div>

    <!-- <h2>Video</h2>
    <p>
      This project studies a phenomenon in cross-attention for multi-domain recommendation models:
      when the cross-attention output becomes increasingly <em>orthogonal</em> to the query representation,
      ranking performance tends to improve. The page includes an anonymized long-form article and an embedded slide deck.
    </p> -->

    <hr>

    <h2>Contents</h2>
    <p>This page is organized as follows:
      <ul>
        <li>Summary Video</li>
        <li>Summary Article</li>
      </ul>
      Summary Video summarizes all the contents of the submitted paper breifly in 15mins -- it's a paraphrase of the submiited paper as video format. 
      Summary Article is a not just a "paraphrase" of the submitted paper. It covers partially --the two main observations out of four main observations in the submitted paper.
      Mostly, it is a much more story-like version of the submitted paper -- which is aimed to be written in a way that is easy to understand and follow for any general audience -- to understand what is our research questions, what is our solution, and what is our message to researchers.    
    </p>

    <p>
      Therefore, we recommend the reader to first take a look at the summary video to grasp what is the paper about at the high level, 
      and then read the summary article to grasp the main observations of the paper.
    </p>


    <hr>


    <h2>Preface</h2>

    <p>This page is excited to share a somewhat counterintuitive phenomenon- <strong>Orthogonal Alignment</strong>‚Äîwith the open-world research community (see Figure 1(b)). Before diving in, a brief disclaimer: this phenomenon has so far been observed only in multi-domain recommendation data, so the author remain cautious about generalizing it to vision-language models (or more broadly, to multi-modal learning).</p>

    <p>That said, This page is optimistic that Orthogonal Alignment may also appear in vision-language settings, given that our study is grounded in transformer architectures with gated cross-attention‚Äîa core component of many modern fusion models. Still, as a researcher, the author want to avoid overgeneralization and therefore frame this observation strictly within the recommendation domain until further studies confirm its presence in vision-language models.</p>

    <p>Ultimately, author's hope is that this discovery inspires new ways of thinking about algorithmic design and sheds light on how to achieve better scaling law in multi-modal models.
    In this post, <strong>the authors want to highlight one simple message</strong>:</p>

    <div style="border: 2px solid; border-image: linear-gradient(90deg, #667eea, #8b9dc3) 1; border-radius: 10px; padding: 20px; margin: 20px 0; box-shadow: 0 3px 10px rgba(102, 126, 234, 0.08); text-align: center;">

    <p><strong><em>When a multi-modal model exhibits the Orthogonal Alignment phenomenon, it tends to improve scaling law.</em></strong></p>

    </div>

    <hr>

    <h2>Summary Video</h2>
    <video controls width="100%" style="border: 1px solid var(--border); border-radius: 14px;">
      <source src="OA_ICML_anonymous.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <div class="small">
      If your browser cannot play the video, you may need to download it or use a different browser by clicking the [materials - video (MP4)] link on the top of the page.
    </div>
    
    <hr>

    <h2>Summary Article</h2>
    <h3>The Rise of Cross-Domain Recommendation Systems</h3>

    
    <div align="center">
      <table>
        <tr>
          <td align="center">
            <img src="./vector_alignment_3d_left.png" alt="Left view of vector alignment" width="400">
            <br>
            <em>(a) Residual Alignment </em>
          </td>
          <td align="center">
            <img src="./vector_alignment_3d_right.png" alt="Right view of vector alignment" width="400">
            <br>
            <em>(b) Orthogonal Alignment </em>
          </td>
          <td align="center">
            <img src="./CA.png" alt="Right view of vector alignment" width="320">
            <br>
            <em>(c) Cross-attention</em>
          </td>
        </tr>
      </table>
      <em>Figure 1: <strong>Conceptual illustration of Orthogonal Alignment.</strong><br>
        Given a source representation vector <span style="color: #d62728;"><strong>Y</strong></span> from domain B, suppose the algorithm progressively updates target representation vector <span style="color: #1f77b4;"><strong>X</strong></span> from domain A throughout training iterations {X‚ÇÅ, X‚ÇÇ, ‚ãØ, X‚Ä≤}.<br>
        <strong>(a) Residual alignment:</strong> The prevailing view of cross-attention is that it refines <span style="color: #1f77b4;"><strong>X</strong></span> by reducing irrelevant and preserving relevant information by referring <span style="color: #d62728;"><strong>Y</strong></span> to update <span style="color: #1f77b4;"><strong>X‚Ä≤</strong></span>.<br>
        <strong>(b) Orthogonal Alignment:</strong> We observe a complement-discovery phenomenon where <span style="color: #1f77b4;"><strong>X‚Ä≤</strong></span> becomes increasingly orthogonal to <span style="color: #1f77b4;"><strong>X</strong></span> as model performance improves. We show that this orthogonality emerges because cross-attention enables parameter-efficient scaling by extracting complementary information from an orthogonal manifold <span style="color: #1f77b4;"><strong>T(X)</strong></span>, thus enhancing performance without a proportional increase in parameters.<br>
        (c) <span style="color: #1f77b4;"><strong>X‚Ä≤</strong></span> is the output of cross-attention, with <span style="color: #1f77b4;"><strong>X</strong></span> as the query and <span style="color: #d62728;"><strong>Y</strong></span> as the key and value.</em>
    </div>





    <p>Imagine you have a dataset D‚ÇÅ=(X‚ÇÅ,Z) and want to build a model that predicts a binary label Z from input X‚ÇÅ. In many real-world cases, the label Z is <em>extremely</em> sparse ‚Äî meaning that most of the values are just zeros.</p>

    <p>When the author worked on the Ranking AI Research team at a large-scale industry platform, one of my main tasks was building recommendation models that display sponsored posts (ads) on a social platform and a social platform (If user clicks an ad, that's how a large-scale industry platform earns moneyüí∞). The key challenge was data sparsity‚Äîusers <strong>rarely</strong> clicked on ads, often engaging with only one out of ten sponsored posts, or sometimes none at all. In practice, even though the model continuously recommended posts over every minites -- say, X‚ÇÅ(14:00), X‚ÇÅ(14:01), X‚ÇÅ(14:02), X‚ÇÅ(14:03)..., -- most of these interactions resulted in no clicks, leaving almost all corresponding outcomes as Z = 0.</p>

    <p>Since high-quality recommendations rely on accurately modeling user engagement, this extreme sparsity made it difficult to infer user intent. In other words, simply training on D‚ÇÅ was not enough to build a truly effective recommendation system.</p>

    <p>One effective way to address this problem is to incorporate richer signals from other domains D‚ÇÇ=(X‚ÇÇ,Z) ‚Äî for example, how long a user stays on which type of post or whether they leave a comment or have shared with others. These additional behavioral cues provide valuable context about user interests and help reduce the impact of sparse labels of other domain D‚ÇÅ.</p>

    <p>This observation motivates a central research problem in multi-modal learning -- <em>developing architectural principles that enable the effective fusion of heterogeneous behavioral modalities</em>.</p>

    <p>A widely adopted solution is the <strong>cross-attention</strong> mechanism, which learns to align and project information from different domains into a shared latent space. This allows the model to combine diverse signals and better capture a user's overall intent ‚Äî even when direct click data is scarce.</p>

    <hr>

    <h2>What Cross-Attention do?: Residual Alignment View</h2>

    <p>Despite its popularity, the internal mechanisms of cross-attention across domains remain poorly understood and are largely explored through empirical studies.</p>

    <p>So far, current research views cross-attention as enabling one domain (<span style="color: #1f77b4;"><strong>X</strong></span> in Figure 1c) to query another (<span style="color: #d62728;"><strong>Y</strong></span> in Figure 1c) and integrate only the most relevant information (<span style="color: #1f77b4;"><strong>X'</strong></span> as a weighted sum of <span style="color: #d62728;"><strong>Y</strong></span> in Figure 1c).</p>

    <p>A growing body of empirical evidence supports this view, especially in various multi-modal models:</p>

    <ul>
      <li>In text-to-image diffusion, cross-attention maps reveal faithful token-to-region correspondences, acting as denoising and relevance filters rather than as indiscriminate fusion.</li>
      <li>In representation disentanglement, cross-attention functions as an inductive bias, promoting the separation of complementary factors and encouraging aligned, non-redundant representations.</li>
      <li>In vision-language model, studies aligning attention maps with human gaze patterns show that effective cross-attention concentrates on causally relevant regions, confirming its selective filtering behavior.</li>
    </ul>

    <p>Therefore, understanding cross-attention as a <strong>"residual alignment"</strong> mechanism is the prevalent interpretation within the research community.</p>

    <div style="border: 2px solid; border-image: linear-gradient(90deg, #667eea, #8b9dc3) 1; border-radius: 10px; padding: 20px; margin: 20px 0; box-shadow: 0 3px 10px rgba(102, 126, 234, 0.08); text-align: center;">

    <p>Current research interprets cross-attention as primarily a <strong>residual alignment</strong> mechanism, where the output (<span style="color: #1f77b4;"><strong>X‚Ä≤</strong></span>) is generated by removing redundant information and preserveing relevant content from the input (<span style="color: #1f77b4;"><strong>X</strong></span>) by referencing another domain (<span style="color: #d62728;"><strong>Y</strong></span>).</p>

    </div>

    <hr>

    <h2>Orthogonal Alignment</h2>

    <p>This work challenges this conventional view and uncovers a new, counter-intuitive mechanism of cross-attention.</p>

    <div style="border: 2px solid; border-image: linear-gradient(90deg, #667eea, #8b9dc3) 1; margin: 20px 0; box-shadow: 0 3px 10px rgba(102, 126, 234, 0.08); overflow: hidden; padding: 0;">

    <div style="background: linear-gradient(90deg, #667eea, #8b9dc3); color: white; padding: 12px 20px; font-weight: 600; font-size: 14px; margin: 0;">
        A Co-Existence Observation in Multi-Modal Learning
      </div>
      <div style="padding: 10px; text-align: center;">
        <strong><em>We argue that two contrasting alignment mechanisms are able to co-exist in cross attention:
        <br><br>
        1. Residual Alignment (conventional view)<br>
        2. Orthogonal Alignment (our discovery)</em></strong>
      </div>

    </div>

    <p>We define an Orthogonal Alignment Phenomenon as follows.</p>

    <div style="border: 2px solid; border-image: linear-gradient(90deg, #667eea, #8b9dc3) 1; border-radius: 10px; padding: 20px; margin: 20px 0; box-shadow: 0 3px 10px rgba(102, 126, 234, 0.08); text-align: center;">

    <p><strong>
    <em>An Orthogonal Alignment is a phenomenon where the input query (<span style="color: #1f77b4;"><strong>X</strong></span>) and the output (<span style="color: #1f77b4;"><strong>X'</strong></span>) of the cross-attention are orthogonal, rather than simply reinforcing the existing pre-aligned features of <span style="color: #1f77b4;"><strong>X</strong></span> when updating to <span style="color: #1f77b4;"><strong>X'</strong></span>
    </em></strong></p>

    </div>

    <p>Please refer to Figure 1 for a visual illustration of this phenomenon, contrasted with the conventional residual-alignment perspective.</p>

    <h3>What is role of <span style="color: #d62728;"><strong>Y</strong></span> in Orthogonal Alignment?</h3>

    <p>After reading the above definition of Orthogonal Alignment, a natural question arises: "Then, what is the role of <span style="color: #d62728;"><strong>Y</strong></span>?" </p>

    <p>My interpretation is that the query <span style="color: #d62728;"><strong>Y</strong></span> functions as a guide that identifies which directions on the tangent space of <span style="color: #1f77b4;"><strong>X</strong></span> correspond to positive transfer signals. More concretely, consider the tangent space of <span style="color: #1f77b4;"><strong>X</strong></span>. Within this space, there exist multiple orthogonal directions‚Äîsome leading to negative transfer, others contributing to positive transfer. In principle, all of these directions could serve as candidates for <span style="color: #1f77b4;"><strong>X‚Ä≤</strong></span>, since they are orthogonal to the original <span style="color: #1f77b4;"><strong>X</strong></span>. Then, the introduction of <span style="color: #d62728;"><strong>Y</strong></span> provides the crucial signal that distinguishes among these directions‚Äîindicating which orthogonal components are constructive (positive transfer) and should therefore be incorporated into <span style="color: #1f77b4;"><strong>X‚Ä≤</strong></span>.</p>

    <p>Intuitively, <span style="color: #d62728;"><strong>Y</strong></span> acts as a directional filter that orients the orthogonal updates toward beneficial regions of the feature manifold, enabling cross-attention to expand representational capacity without amplifying redundant correlations.</p>

    <h3>Experiment results.</h3>

    <p>Empirically, we observe that the Gated Cross-Attention (GCA) module enhances recommendation performance by generating outputs that are not merely filtered versions of the input query(See Figure 2). In simple terms, GCA introduces a learnable gating mechanism that combines the input and the cross-attention output as <span style="color: #1f77b4;"><strong>X</strong></span> + Œ±<span style="color: #1f77b4;"><strong>X'</strong></span>  where <span style="color: #1f77b4;"><strong>X'</strong></span> is the output of cross attention and Œ± is a learnable parameter. This formulation allows the model to produce complementary representations‚Äîcapturing aspects of the input query that were previously underrepresented or unseen.</p>

    <p>We evaluated this effect using three recent Cross-Domain Sequential Recommendation (CDSR) models: LLM4CDSR¬π, CDSRNP¬≤, and ABXI¬≥ -- all of which are transformer-based architectures reported as state-of-the-art in their respective papers. In Figure 2, the evaluation metric NDCG@10 (Normalized Discounted Cumulative Gain at rank 10) measures how accurately each model ranks the top 10 items compared with the ground-truth order‚Äîthat is, how well it predicts both which items should appear and in what order. The x-axis represents the absolute value of the cosine similarity between <span style="color: #1f77b4;"><strong>X</strong></span> and <span style="color: #1f77b4;"><strong>X‚Ä≤</strong></span> for both Domain A and Domain B, where the blue dots correspond to Domain A and the red dots correspond to Domain B.</p>

    <p>To ensure robustness, we conducted experiments with multiple random initializations, several GCA architectural variants, and different datasets. Each configuration corresponds to one datapoint in the three subfigures below, and each point represents the best test results from its train process.</p>

    <p>Overall, the results consistently demonstrate that the Orthogonal Alignment effect‚Äîinduced by GCA‚Äîleads to model performance increases: <strong>Lower cosine similarity indicates stronger orthogonal alignment, which tends to correlate with higher NDCG@10</strong>.</p>

    <div align="center">

    <p><table>
        <tr>
          <td align="center">
            <img src="./cdsrnp_cos_NDCG@10.png" alt="cdsrnp" width="400">
            <br>
            <em>(a)CDSRNP </em>
          </td>
          <td align="center">
            <img src="./abxi_cos_NDCG@10.png" alt="abxi" width="400">
            <br>
            <em>(b) ABXI </em>
          </td>
          <td align="center">
            <img src="./llm4cdsr_cos_NDCG@10.png" alt="llm4cdsr" width="400">
            <br>
            <em>(b) LLM4CDSR</em>
          </td>
        </tr>
      </table>
      <em>Figure2. We observed that the gated cross-attention module introduces an unseen, orthogonal feature representation: as the input query <span style="color: #1f77b4;"><strong>X</strong></span> and its cross-attended output <span style="color: #1f77b4;"><strong>X'</strong></span> (conditioned on key and value <span style="color: #d62728;"><strong>Y</strong></span>) become more orthogonal, the ranking performance improves. Blue color dots are domain A and red color dots are domain B</em></p>

    </div>

    <hr>

    <h2>Orthogonal Alignment improves scaling law</h2>

    <p>Crucially, we classify orthogonal alignment as a <strong>phenomenon</strong> because we empirically show that it <strong>emerges naturally</strong>, without requiring <strong>ANY</strong> explicit orthogonality regularization in either:  Loss formulation or Model architecture. So why this pheomena just naturally happens? This is where this works' main contribution comes from.</p>

    <p>We argue that this phenomenon improves scaling law in multi-modal model:</p>

    <div style="border: 2px solid; border-image: linear-gradient(90deg, #667eea, #8b9dc3) 1; border-radius: 10px; padding: 20px; margin: 20px 0; box-shadow: 0 3px 10px rgba(102, 126, 234, 0.08); text-align: center;">

    <p><strong><em>Hypothesis: Orthogonal Alignment improves scaling law in multi-modal model.</em></strong></p>

    </div>

    <p>By ensuring that updates occupy subspace orthogonal to the input query, the model gains new representational capacity without needing more parameters.</p>

    <p>We compare two approaches:</p>
    <ol>
      <li>Baseline + GCA module</li>
      <li>Parameter-augmented baseline (simply increasing parameters)</li>
    </ol>

    <p>For instance, suppose the baseline model has 2 M parameters and the GCA module adds 0.5 M. To make the comparison fair, we also evaluate a parameter-augmented baseline with 2.5 M parameters‚Äîmatching the total parameter count of the GCA-enhanced model. </p>

    <p><strong>We observed that the Baseline + GCA consistently outperformed the parameter-augmented baseline, demonstrating that the performance gain comes from orthogonal alignment rather than mere model scaling</strong> (see Figure 3).</p>

    <p>In Figure 3, Baseline + GCA<sub>early</sub> refers to inserting a single GCA module at the early stage of the model, while Baseline + GCA<sub>stack</sub> denotes stacking multiple GCA modules vertically throughout the network‚Äîfrom early to later layers.</p>

    <div align="center">

    <p><table>
        <!-- First row: 3 figures -->
        <tr>
          <td align="center">
            <img src="./model_comparison_plot_cdsrnp.png" alt="cdsrnp" width="200">
            <br>
            <em>(a) CDSRNP </em>
          </td>
          <td align="center">
            <img src="./model_comparison_plot_abxi_abe.png" alt="abxi" width="200">
            <br>
            <em>(b) ABXI </em>
          </td>
          <td align="center">
            <img src="./model_comparison_plot_abxi_afk.png" alt="abxi" width="200">
            <br>
            <em>(c) ABXI </em>
          </td>
        </tr>
        <!-- Second row: 2 figures -->
        <tr>
          <td align="center">
            <img src="./model_comparison_plot_llm4cdsr_amazon.png" alt="llm4cdsr" width="200">
            <br>
            <em>(d) LLM4CDSR </em>
          </td>
          <td align="center">
            <img src="./model_comparison_plot_llm4cdsr_elec.png" alt="llm4cdsr" width="200">
            <br>
            <em>(e) LLM4CDSR </em>
          </td>
          <td align="center">
            <!-- Empty cell to maintain table structure -->
          </td>
        </tr>
      </table></p>

    <p><em>Figure 3: NDCG@10 comparison between baseline and baseline + gated cross attention model</em></p>

    </div>

    <p>First, our results show that across all five experimental cases, the addition of baseline with GCA_early consistently yields higher single-domain ranking performance (Domain A's NDCG@10) compared to parameter-matched baselines, while Domain B's NDCG@10 also shows general improvement.</p>

    <p>Moreover, in both LLM4CDSR settings, GCA<sub>early</sub> demonstrates the strongest parameter efficiency. We attribute this advantage to the fixed hidden dimensionality of the initial embedding vectors inherited from the pretrained LLM, which constrains the representational capacity of the baseline model. As a result, simply scaling up the baseline parameters eventually leads to performance saturation‚Äîand in some cases, degradation‚Äîas model size increases.</p>

    <p>In contrast, introducing orthogonal alignment through GCA enables more effective information extraction under limited representational capacity. This property allows GCA to achieve a superior accuracy-per-parameter trade-off, demonstrating a more efficient use of model capacity.</p>

    <h2>Concluding Remark: Toward Vision‚ÄìLanguage Generalization</h2>

    <p>We remain cautious about generalizing our findings to vision‚Äìlanguage models, since all of our experiments on Orthogonal Alignment were conducted exclusively with recommendation data. Nonetheless, we are optimistic that similar phenomena could emerge in vision‚Äìlanguage settings, given that our study also relies on transformer architectures with gated cross-attention‚Äîa core component in many multi-modal models.</p>

    <p>The key distinctions between our setting and typical vision‚Äìlanguage architectures are as follows:</p>

    <ul>
      <li><p>Our observations of orthogonal alignment were made using recommendation data, where encoder representations were not pre-aligned.</p></li>
      <li><p>Vision‚Äìlanguage models, in contrast, generally employ pretrained image and text encoders that produce highly aligned representations by design.</p></li>
    </ul>

    <p>This difference matters because most vision‚Äìlanguage encoders are trained using self-contrastive objectives, which explicitly encourage high cosine similarity between matching image‚Äìtext pairs and low similarity between mismatched ones. As a result, their latent representations are already well-aligned before cross-attention is applied‚Äîpotentially making orthogonal alignment less pronounced or more difficult to observe directly.</p>

    <p>Therefore, while we expect Orthogonal Alignment to exist in vision‚Äìlanguage models, it may manifest under more subtle and nuanced conditions, reflecting the already pre-aligned nature of their learned embeddings.</p>

    <hr>

    <p><strong>References:</strong></p>

    <p>¬π LLM4CDSR: Liu, Qidong, et al. "Bridge the Domains: Large Language Models Enhanced Cross-domain Sequential Recommendation." Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2025. </p>

    <p>¬≤ CDSRNP: Li, Haipeng, et al. "Cross-Domain Sequential Recommendation via Neural Process." a preprint server preprint a preprint server:2410.13588 (2024).</p>

    <p>¬≥ ABXI: Bian, Qingtian, et al. "ABXI: invariant interest adaptation for task-guided cross-domain sequential recommendation." Proceedings of the ACM on Web Conference. 2025.</p>
  </div>
</body>
</html>
